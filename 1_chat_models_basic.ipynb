{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![MGB Logo](https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/mgb-logo.png?raw=true)\n",
    "\n",
    "# Using LLM for Clinical Note Analysis\n",
    "This Notebook demonstrates how to use Azure-hosted OpenAI models with LangChain. The notebook follows a step-by-step approach to set up authentication, initialize the model, create structured prompts, and generate responses. The key components covered include:#\n",
    "\n",
    "- Loading environment variables\n",
    "- Setting up Azure authentication\n",
    "- Creating and formatting chat prompts\n",
    "- Invoking the OpenAI model\n",
    "- Displaying the AI-generated response\n",
    "\n",
    "Each cell in the notebook builds upon the previous one to progressively set up and execute an AI-driven conversation."
   ],
   "id": "a2b994958c92d3b8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-25T20:34:28.949876Z",
     "start_time": "2025-02-25T20:34:28.944893Z"
    }
   },
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Importing Required Libraries\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates the necessary imports for setting up Azure OpenAI authentication and model interaction.\n",
    "\n",
    "# Key Components:\n",
    "#   - os: Provides functions for interacting with the operating system, such as accessing environment variables.\n",
    "#   - load_dotenv(): Loads environment variables from a .env file to securely store sensitive credentials.\n",
    "#   - DefaultAzureCredential: Handles authentication with Azure services using various credential methods.\n",
    "#   - get_bearer_token_provider(): Retrieves an authentication token for accessing Azure OpenAI services.\n",
    "#   - AzureChatOpenAI: A LangChain wrapper for interacting with Azure-hosted OpenAI models.\n",
    "\n",
    "# Purpose:\n",
    "# These libraries enable secure authentication and seamless integration of OpenAI models within Azure,\n",
    "# ensuring that AI capabilities can be efficiently accessed and utilized in applications.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "print(\"\\n=== Required Libraries Loaded ===\")\n"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T01:31:17.619667Z",
     "start_time": "2025-02-27T01:31:17.458004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Setting Up Azure OpenAI Model\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to configure and authenticate Azure OpenAI for use in AI-driven applications.\n",
    "\n",
    "# Key Components:\n",
    "#   - load_dotenv(): Loads environment variables from a .env file to securely store credentials.\n",
    "#   - DefaultAzureCredential(): Uses Azure’s default authentication method to retrieve credentials.\n",
    "#   - get_bearer_token_provider(): Retrieves an authentication token for accessing Azure OpenAI services.\n",
    "#   - AzureChatOpenAI(): Initializes the Azure-hosted OpenAI model using environment variables.\n",
    "#     - openai_api_version: Specifies the API version to use.\n",
    "#     - azure_deployment: Identifies the specific OpenAI deployment.\n",
    "#     - azure_endpoint: Defines the Azure endpoint for API access.\n",
    "#     - azure_ad_token_provider: Supplies the necessary authentication token.\n",
    "\n",
    "# Purpose:\n",
    "# This setup ensures secure and efficient access to Azure OpenAI services, enabling seamless integration of AI capabilities into applications.\n",
    "# It provides a scalable way to interact with OpenAI models hosted on Azure while managing authentication automatically.\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Azure credentials and token provider\n",
    "azure_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    azure_credential, \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# Initialize the AzureChatOpenAI model using environment variables\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=token_provider\n",
    ")\n",
    "\n",
    "print(\"\\n=== LLM Models Loaded ===\")\n"
   ],
   "id": "e4ab2139560c3664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LLM Models Loaded ===\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Basic Prompt Interaction\n",
    "<img src=\"https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/basic_prompt.png?raw=true\" alt=\"Basic Prompt\" width=\"800\">"
   ],
   "id": "a8a750da658a7524"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:36:57.264527Z",
     "start_time": "2025-02-25T20:36:41.940357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. Basic Prompt Interaction\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates a simple prompt-based interaction with an AI model using LangChain.\n",
    " \n",
    "# Key Components:\n",
    "#   - SystemMessage: Defines the AI’s role as a medical provider, ensuring responses are evidence-based and patient-friendly.\n",
    "#   - HumanMessage: Represents the user's query, in this case: \"What is asthma? What are its common symptoms and treatments?\"\n",
    "#   - model.invoke(messages): Sends the conversation history to the AI model, prompting it to generate a response.\n",
    "\n",
    "# Purpose: \n",
    "# This setup enables structured AI interactions, ensuring the model responds consistently and accurately in a medical context.\n",
    "# Can be extended to handle more complex medical queries or chatbot interactions.\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define a chat interaction using a system message (to set the AI’s role) and a human message (a user query about asthma).\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a knowledgeable medical provider with expertise in diagnosing and managing various diseases. Provide clear, evidence-based, and patient-friendly explanations about medical conditions, symptoms, and treatments.\"),\n",
    "    \n",
    "    HumanMessage(content=\"What is asthma? What are its common symptoms and treatments?\")\n",
    "]\n",
    "\n",
    "# Invoke the model with messages\n",
    "result = model.invoke(messages)\n",
    "\n",
    "print(result.content)"
   ],
   "id": "c84f9839d5749e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma is a chronic respiratory condition characterized by inflammation and narrowing of the airways, which can make breathing difficult. This condition can vary in severity and may trigger during specific situations, such as exercise or exposure to allergens.\n",
      "\n",
      "### Common Symptoms of Asthma\n",
      "1. **Shortness of Breath:** Difficulty breathing or feeling breathless.\n",
      "2. **Wheezing:** A squeaky or whistling sound when you breathe.\n",
      "3. **Chest Tightness:** A feeling of pressure or tightness in the chest.\n",
      "4. **Coughing:** Particularly at night or early morning, or when exposed to cold air or exercise.\n",
      "5. **Difficulty Sleeping:** Due to shortness of breath, coughing, or wheezing.\n",
      "\n",
      "### Triggers\n",
      "Certain factors can exacerbate asthma symptoms, including:\n",
      "- Allergens (pollen, dust mites, pet dander)\n",
      "- Irritants (smoke, pollution, strong odors)\n",
      "- Physical activity\n",
      "- Cold air\n",
      "- Respiratory infections (such as colds or the flu)\n",
      "- Stress and strong emotions\n",
      "\n",
      "### Treatment Options\n",
      "1. **Long-term control medications:** \n",
      "   - **Inhaled corticosteroids** (e.g., fluticasone, budesonide): Reduce inflammation and prevent symptoms.\n",
      "   - **Leukotriene modifiers** (e.g., montelukast): Help by blocking substances in the body that cause asthma symptoms.\n",
      "   - **Long-acting beta agonists (LABAs)** (e.g., salmeterol, formoterol): Used in conjunction with inhaled corticosteroids to help keep airways open.\n",
      "   - **Combination inhalers:** Contain both corticosteroids and LABAs.\n",
      "\n",
      "2. **Quick-relief (rescue) medications:**\n",
      "   - **Short-acting beta agonists (SABAs)** (e.g., albuterol): Provide quick relief of asthma symptoms by relaxing the muscles around the airways.\n",
      "   - **Anticholinergics** (e.g., ipratropium): Help open airways and are sometimes used for severe asthma.\n",
      "\n",
      "3. **Biologics:** For severe asthma, these are injectable medications that target specific cells or proteins in the body to reduce inflammation (e.g., omalizumab, mepolizumab).\n",
      "\n",
      "4. **Avoidance of Triggers:** Identifying and minimizing exposure to asthma triggers is crucial for managing the condition effectively.\n",
      "\n",
      "5. **Asthma Action Plan:** A personalized management plan developed with your healthcare provider to monitor symptoms and adjust treatment as needed.\n",
      "\n",
      "### Managing Asthma\n",
      "- **Regular Monitoring:** Measure lung function and keep track of symptoms to manage asthma effectively.\n",
      "- **Education:** Learn how to use inhalers properly and understand the importance of medication adherence.\n",
      "- **Healthy Lifestyle:** Maintain a balanced diet, stay active within your limits, and avoid smoking.\n",
      "\n",
      "Asthma is a manageable condition with the right approach and treatment plan. If you have concerns or experience persistent symptoms, it’s important to consult your healthcare provider for an accurate diagnosis and personalized management strategy.\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:42:00.190194Z",
     "start_time": "2025-02-27T15:41:56.188147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4. Using ChatPromptTemplate for Dynamic Queries\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to create a reusable prompt template with dynamic input variables using LangChain.\n",
    "\n",
    "# Key Components:\n",
    "#   - ChatPromptTemplate: Allows dynamic variables in prompts, making interactions more flexible.\n",
    "#   - SystemMessage: Sets the AI’s role as a medical provider, ensuring responses are clear and evidence-based.\n",
    "#   - HumanMessage: Contains a query template with a placeholder ({disease}), allowing different medical conditions to be queried dynamically.\n",
    "#   - prompt_template.invoke({\"disease\": disease}): Fills in the variable \"disease\" with the specified condition (e.g., \"epilepsy\").\n",
    "#   - model.invoke(prompt): Sends the formatted query to the AI model for a response.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables reusable prompts where users can query different diseases without modifying the prompt structure.\n",
    "# It improves scalability and efficiency for medical applications or chatbots handling multiple medical conditions.\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "ai_role = \"Neurologist\"\n",
    "disease = \"epilepsy\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", f\"You are a knowledgeable {ai_role} with expertise in diagnosing and managing various diseases. Provide clear, evidence-based, and patient-friendly explanations about medical conditions, symptoms, and treatments.\"),\n",
    "    \n",
    "    (\"human\", \"What is {disease}? What are its common symptoms and treatments?\"),\n",
    "]\n",
    "# Create PromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Plug-in user variables\n",
    "prompt = prompt_template.invoke({\"ai_role\": ai_role , \"disease\": disease})\n",
    "\n",
    "# invoke model\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ],
   "id": "ff4be7952c8bc9f9",
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'code': '403', 'message': 'Public access is disabled. Please configure private endpoint.'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPermissionDeniedError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[110], line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m prompt \u001B[38;5;241m=\u001B[39m prompt_template\u001B[38;5;241m.\u001B[39minvoke({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisease\u001B[39m\u001B[38;5;124m\"\u001B[39m: disease})\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# invoke model\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mprint\u001B[39m(result\u001B[38;5;241m.\u001B[39mcontent)\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:284\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    280\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    281\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    283\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 284\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    294\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:860\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    854\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    858\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    859\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 860\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:690\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 690\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    696\u001B[0m         )\n\u001B[1;32m    697\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    698\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:925\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    923\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 925\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    929\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:783\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    781\u001B[0m     generation_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response\u001B[38;5;241m.\u001B[39mheaders)}\n\u001B[1;32m    782\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 783\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response, generation_info)\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:879\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    839\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    876\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    877\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    878\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m--> 879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    898\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    914\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    915\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    916\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/openai/_base_client.py:1290\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1276\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1278\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1285\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1286\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1287\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1288\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1289\u001B[0m     )\n\u001B[0;32m-> 1290\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/openai/_base_client.py:967\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    965\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venvs/mongan_llm_workshop/lib/python3.12/site-packages/openai/_base_client.py:1071\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1068\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1070\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1071\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1074\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1075\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1079\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1080\u001B[0m )\n",
      "\u001B[0;31mPermissionDeniedError\u001B[0m: Error code: 403 - {'error': {'code': '403', 'message': 'Public access is disabled. Please configure private endpoint.'}}"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:39:53.090348Z",
     "start_time": "2025-02-25T20:39:53.086493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5. Using ChatPromptTemplate for Clinical Note Analysis\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to create a structured prompt template for extracting medical details from clinical notes.\n",
    "\n",
    "# Key Components:\n",
    "#   - ChatPromptTemplate: Creates a reusable prompt structure for analyzing clinical notes.\n",
    "#   - SystemMessage: Defines the AI’s role as a medical documentation assistant, ensuring accurate extraction of medical details.\n",
    "#   - HumanMessage: Contains a structured query with a placeholder ({patient_note}), allowing different clinical notes to be analyzed dynamically.\n",
    "#   - prompt_template_notes.invoke({\"patient_note\": note_text}): Fills in the variable \"patient_note\" with the actual clinical note text.\n",
    "#   - model.invoke(prompt): Sends the formatted query to the AI model for processing.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables automated medical text processing, ensuring structured extraction of relevant information such as demographics, chief complaints, medications, and asthma status.\n",
    "# It improves efficiency in clinical documentation and can be integrated into medical record systems for automated analysis.\n",
    "\n",
    "\n",
    "messages_notes = [\n",
    "    (\n",
    "        \"system\", \n",
    "        \"You are an advanced medical documentation assistant with expertise in clinical text analysis. Your task is to review a given clinical note and extract relevant medical details accurately.\"\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        \"human\", \n",
    "        \"Please analyze the following clinical note: {patient_note}. \\n\\n\"\n",
    "        \"Extract and list the following information:\\n\"\n",
    "        \"1. Patient demographics\\n\"\n",
    "        \"2. Chief Complaints\\n\"\n",
    "        \"3. Current Medications\\n\"\n",
    "        \"4. Determine whether the patient has asthma (Yes/No), based on explicit mentions or related diagnoses.\\n\\n\"\n",
    "        \"Provide the output in a structured format.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt_template_notes = ChatPromptTemplate.from_messages(messages_notes)\n"
   ],
   "id": "2f958c9284e3da1f",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:43:18.888332Z",
     "start_time": "2025-02-25T20:43:18.882440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 6. Loading and Reading a Patient Note\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to load a clinical note from a file for further processing.\n",
    "\n",
    "# Key Components:\n",
    "#   - input_dir: Specifies the directory where patient notes are stored.\n",
    "#   - filename: Defines the specific file to be loaded, containing a patient's medical note.\n",
    "#   - os.path.join(input_dir, filename): Constructs the full file path dynamically.\n",
    "#   - open(file_path, \"r\"): Opens the file in read mode and loads the content into the variable \"patient_note\".\n",
    "#   - print(f\"\\nPatient Note:\\n\\n{patient_note}\"): Displays the loaded note for verification.\n",
    "\n",
    "# Purpose:\n",
    "# This step ensures that patient notes are correctly loaded before being analyzed by the AI model.\n",
    "# It enables seamless integration with document processing pipelines for clinical text analysis.\n",
    "\n",
    "\n",
    "input_dir = 'data_prep/patient_notes'\n",
    "filename = 'note_1000000013_20091210.txt' \n",
    "\n",
    "# examples without Asthma: \n",
    "# -----------------------------------------------------------\n",
    "# 1000000002, 1000000003, 1000000009, 1000000010, 1000000013, \n",
    "# 1000000023, 1000000036, 1000000040, 1000000047, 1000000048, \n",
    "# 1000000052, 1000000063, 1000000064, 1000000068, 1000000071, \n",
    "# 1000000082, 1000000086, 1000000087, 1000000093, 1000000101, \n",
    "# 1000000103, 1000000107\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Load the note txt\n",
    "file_path = os.path.join(input_dir, filename)\n",
    "with open(file_path, \"r\") as file:\n",
    "    patient_note = file.read()\n",
    "    \n",
    "print(f\"\\nPatient Note:\\n\\n{patient_note}\")"
   ],
   "id": "ed77019c319ec4f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient Note:\n",
      "\n",
      "This is an 84-year-old Black female who has been receiving care at our clinic for several years and primarily communicates in German with the assistance of a translator. On 12/10/2009, she presents for a routine follow-up. The patient reports feeling generally more fatigued and weaker than usual over the past month. She also describes intermittent dizziness and persistent shortness of breath on exertion. She denies experiencing any fever, night sweats, or unexplained weight loss. \n",
      "\n",
      "Her past medical history includes hypertension, chronic kidney disease, congestive heart failure, type II diabetes mellitus, a calcaneal spur, osteoporosis, and has undergone a complete thyroidectomy. Her surgical history also includes endoscopic biopsy of the large intestine and a closed [endoscopic] biopsy for breast screening. Her current medications include Lisinopril for hypertension, Furosemide for congestive heart failure and fluid management, Metformin for diabetes mellitus, and a daily aspirin for cardiovascular prophylaxis. She has been adherent to her medication regimen and reports no significant side effects.\n",
      "\n",
      "Socially, the patient is a retired school teacher, living independently but maintaining close contact with her children. She has never smoked, does not consume alcohol, and leads a relatively sedentary lifestyle. She has no known allergies.\n",
      "\n",
      "Subjectively, the patient’s primary complaints are fatigue and generalized weakness. She describes the onset of these symptoms as gradual, with no specific exacerbating or alleviating factors noted. The intermittent dizziness and shortness of breath appear to worsen with physical exertion. \n",
      "\n",
      "On physical examination, her vital signs were recorded as follows: blood pressure 145/85 mmHg, heart rate 82 bpm, respiratory rate 18 breaths per minute, temperature 98.7°F (37.1°C), and oxygen saturation 97% on room air.\n",
      "\n",
      "Observing her general appearance, she appeared well-nourished and in no acute distress. She was alert and oriented to time, place, and person.\n",
      "\n",
      "Cardiovascular examination revealed a regular heart rhythm without murmurs, rubs, or gallops. Peripheral pulses were strong and symmetrical, and there was no jugular venous distention.\n",
      "\n",
      "The respiratory examination showed clear breath sounds bilaterally without wheezing, rales, or rhonchi.\n",
      "\n",
      "An abdominal examination revealed a soft and non-tender abdomen with normal bowel sounds. There were no signs of hepatosplenomegaly or masses.\n",
      "\n",
      "Neurologically, cranial nerves II-XII were intact. Motor strength and sensation were normal in all extremities, with symmetrical reflexes. Coordination and gait were also normal.\n",
      "\n",
      "Musculoskeletal examination noted no joint deformities or swelling. The patient exhibited a full range of motion in all extremities, with no tenderness or erythema.\n",
      "\n",
      "The skin was warm, dry, and intact, with no visible rashes, bruises, or lesions.\n",
      "\n",
      "Recent laboratory findings included normal levels of Hematocrit, Hemoglobin, Mean Corpuscular Volume, Mean Corpuscular Hemoglobin Concentration, Platelets, and White Blood Cell count with a normal differential. Electrolyte levels, including Sodium and Potassium, were within normal limits. Kidney function tests, including Creatinine and Blood Urea Nitrogen, remained stable.\n",
      "\n",
      "Assessment:\n",
      "1. **Hypertension:** Blood pressure is slightly elevated today indicating a potential need for medication adjustment.\n",
      "2. **Chronic Kidney Disease:** Labs show the condition is stable and continuous monitoring is essential.\n",
      "3. **Congestive Heart Failure:** Stable with current management, showing no signs of heart failure exacerbation.\n",
      "4. **Type II Diabetes Mellitus:** Blood glucose managed well with Metformin, though regular monitoring remains critical.\n",
      "5. **Fatigue and Generalized Weakness:** Likely secondary to the patient’s chronic conditions; further evaluation for anemia and potential electrolyte imbalances is necessary.\n",
      "\n",
      "Plan:\n",
      "1. **Hypertension:** Continue Lisinopril, advise regular home monitoring of blood pressure.\n",
      "2. **Chronic Kidney Disease:** Maintain current Furosemide dosage, promote a low sodium diet, and perform follow-up renal function tests including serum Creatinine and Blood Urea Nitrogen.\n",
      "3. **Congestive Heart Failure:** Continue with current Furosemide management, monitor for symptoms of fluid overload or heart failure exacerbation.\n",
      "4. **Type II Diabetes Mellitus:** Continue Metformin, regular blood glucose monitoring recommended, and HbA1c testing scheduled.\n",
      "5. **Fatigue and Generalized Weakness:** Order a Complete Blood Count and a Comprehensive Metabolic Panel to rule out anemia or electrolyte disturbances. Gradual increase in physical activity is encouraged as tolerated.\n",
      "\n",
      "Follow-Up:\n",
      "The patient is instructed to contact the clinic if symptoms worsen or do not improve within a week, or if test results indicate further evaluation is needed. A follow-up appointment is scheduled for two weeks to review the laboratory test results and reassess symptoms. The patient has demonstrated understanding of the treatment plan, the importance of medication adherence, lifestyle modifications, and regular monitoring of her health conditions.\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T20:43:27.307390Z",
     "start_time": "2025-02-25T20:43:20.482309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 7. Invoking the AI Model for Clinical Note Analysis\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to process a patient note using a structured prompt and invoke the AI model for analysis.\n",
    "\n",
    "# Key Components:\n",
    "#   - prompt_template_notes.invoke({\"patient_note\": patient_note}): \n",
    "#     Dynamically fills the prompt template with the actual clinical note text.\n",
    "#   - model.invoke(prompt_notes): \n",
    "#     Sends the formatted query to the AI model for processing.\n",
    "#   - print(result_note.content): \n",
    "#     Displays the AI-generated structured output containing extracted medical details.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables automated extraction of structured medical information from clinical notes.\n",
    "# It ensures efficient and standardized processing of patient data, aiding in medical documentation and decision-making.\n",
    "\n",
    "prompt_notes = prompt_template_notes.invoke({\"patient_note\": patient_note})\n",
    "\n",
    "# invoke model\n",
    "result_note = model.invoke(prompt_notes)\n",
    "print(result_note.content)\n"
   ],
   "id": "43a71ee0339c8ac2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Patient demographics:**\n",
      "   - Age: 84 years old\n",
      "   - Gender: Female\n",
      "   - Ethnicity/Race: Black\n",
      "   - Language: Primarily communicates in German with the assistance of a translator\n",
      "\n",
      "2. **Chief Complaints:**\n",
      "   - General fatigue and weakness over the past month\n",
      "   - Intermittent dizziness\n",
      "   - Persistent shortness of breath on exertion\n",
      "   - No fever, night sweats, or unexplained weight loss\n",
      "\n",
      "3. **Current Medications:**\n",
      "   - Lisinopril (for hypertension)\n",
      "   - Furosemide (for congestive heart failure and fluid management)\n",
      "   - Metformin (for type II diabetes mellitus)\n",
      "   - Daily aspirin (for cardiovascular prophylaxis)\n",
      "\n",
      "4. **Asthma Diagnosis:**\n",
      "   - No (The patient does not have asthma, and there are no explicit mentions of asthma or related diagnoses in the clinical note.)\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8e7dc8702f5fdc44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
