{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![MGB Logo](https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/mgb-logo.png?raw=true)\n",
    "\n",
    "# Using LLM for Clinical Note Analysis\n",
    "This Notebook demonstrates how to use Azure-hosted OpenAI models with LangChain. The notebook follows a step-by-step approach to set up authentication, initialize the model, create structured prompts, and generate responses. The key components covered include:#\n",
    "\n",
    "- Loading environment variables\n",
    "- Setting up Azure authentication\n",
    "- Creating and formatting chat prompts\n",
    "- Invoking the OpenAI model\n",
    "- Displaying the AI-generated response\n",
    "\n",
    "Each cell in the notebook builds upon the previous one to progressively set up and execute an AI-driven conversation."
   ],
   "id": "a2b994958c92d3b8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Importing Required Libraries\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates the necessary imports for setting up Azure OpenAI authentication and model interaction.\n",
    "\n",
    "# Key Components:\n",
    "#   - os: Provides functions for interacting with the operating system, such as accessing environment variables.\n",
    "#   - load_dotenv(): Loads environment variables from a .env file to securely store sensitive credentials.\n",
    "#   - DefaultAzureCredential: Handles authentication with Azure services using various credential methods.\n",
    "#   - get_bearer_token_provider(): Retrieves an authentication token for accessing Azure OpenAI services.\n",
    "#   - AzureChatOpenAI: A LangChain wrapper for interacting with Azure-hosted OpenAI models.\n",
    "\n",
    "# Purpose:\n",
    "# These libraries enable secure authentication and seamless integration of OpenAI models within Azure,\n",
    "# ensuring that AI capabilities can be efficiently accessed and utilized in applications.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "print(\"\\n=== Required Libraries Loaded ===\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Setting Up Azure OpenAI Model\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to configure and authenticate Azure OpenAI for use in AI-driven applications.\n",
    "\n",
    "# Key Components:\n",
    "#   - load_dotenv(): Loads environment variables from a .env file to securely store credentials.\n",
    "#   - DefaultAzureCredential(): Uses Azure’s default authentication method to retrieve credentials.\n",
    "#   - get_bearer_token_provider(): Retrieves an authentication token for accessing Azure OpenAI services.\n",
    "#   - AzureChatOpenAI(): Initializes the Azure-hosted OpenAI model using environment variables.\n",
    "#     - openai_api_version: Specifies the API version to use.\n",
    "#     - azure_deployment: Identifies the specific OpenAI deployment.\n",
    "#     - azure_endpoint: Defines the Azure endpoint for API access.\n",
    "#     - azure_ad_token_provider: Supplies the necessary authentication token.\n",
    "\n",
    "# Purpose:\n",
    "# This setup ensures secure and efficient access to Azure OpenAI services, enabling seamless integration of AI capabilities into applications.\n",
    "# It provides a scalable way to interact with OpenAI models hosted on Azure while managing authentication automatically.\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Azure credentials and token provider\n",
    "azure_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    azure_credential, \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# Initialize the AzureChatOpenAI model using environment variables\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=token_provider\n",
    ")\n",
    "\n",
    "print(\"\\n=== LLM Models Loaded ===\")\n"
   ],
   "id": "e4ab2139560c3664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Basic Prompt Interaction\n",
    "<img src=\"https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/basic_prompt.png?raw=true\" alt=\"Basic Prompt\" width=\"800\">"
   ],
   "id": "a8a750da658a7524"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. Basic Prompt Interaction\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates a simple prompt-based interaction with an AI model using LangChain.\n",
    " \n",
    "# Key Components:\n",
    "#   - SystemMessage: Defines the AI’s role as a medical provider, ensuring responses are evidence-based and patient-friendly.\n",
    "#   - HumanMessage: Represents the user's query, in this case: \"What is asthma? What are its common symptoms and treatments?\"\n",
    "#   - model.invoke(messages): Sends the conversation history to the AI model, prompting it to generate a response.\n",
    "\n",
    "# Purpose: \n",
    "# This setup enables structured AI interactions, ensuring the model responds consistently and accurately in a medical context.\n",
    "# Can be extended to handle more complex medical queries or chatbot interactions.\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define a chat interaction using a system message (to set the AI’s role) and a human message (a user query about asthma).\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a knowledgeable medical provider with expertise in diagnosing and managing various diseases. Provide clear, evidence-based, and patient-friendly explanations about medical conditions, symptoms, and treatments.\"),\n",
    "    \n",
    "    HumanMessage(content=\"What is asthma? What are its common symptoms and treatments?\")\n",
    "]\n",
    "\n",
    "# Invoke the model with messages\n",
    "result = model.invoke(messages)\n",
    "\n",
    "print(result.content)"
   ],
   "id": "c84f9839d5749e5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Using ChatPromptTemplate for Dynamic Queries\n",
    "<img src=\"https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/prompt_template.png?raw=true\" alt=\"Basic Prompt\" width=\"800\">\n"
   ],
   "id": "70e18716ffd84a04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4. Using ChatPromptTemplate for Dynamic Queries\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to create a reusable prompt template with dynamic input variables using LangChain.\n",
    "\n",
    "# Key Components:\n",
    "#   - ChatPromptTemplate: Allows dynamic variables in prompts, making interactions more flexible.\n",
    "#   - SystemMessage: Sets the AI’s role as a medical provider, ensuring responses are clear and evidence-based.\n",
    "#   - HumanMessage: Contains a query template with a placeholder ({disease}), allowing different medical conditions to be queried dynamically.\n",
    "#   - prompt_template.invoke({\"disease\": disease}): Fills in the variable \"disease\" with the specified condition (e.g., \"epilepsy\").\n",
    "#   - model.invoke(prompt): Sends the formatted query to the AI model for a response.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables reusable prompts where users can query different diseases without modifying the prompt structure.\n",
    "# It improves scalability and efficiency for medical applications or chatbots handling multiple medical conditions.\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "ai_role = \"Neurologist\"\n",
    "disease = \"epilepsy\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", f\"You are a knowledgeable {ai_role} with expertise in diagnosing and managing various diseases. Provide clear, evidence-based, and patient-friendly explanations about medical conditions, symptoms, and treatments.\"),\n",
    "    \n",
    "    (\"human\", \"What is {disease}? What are its common symptoms and treatments?\"),\n",
    "]\n",
    "# Create PromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Plug-in user variables\n",
    "prompt = prompt_template.invoke({\"ai_role\": ai_role , \"disease\": disease})\n",
    "\n",
    "# invoke model\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ],
   "id": "ff4be7952c8bc9f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5. Using ChatPromptTemplate for Clinical Note Analysis\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to create a structured prompt template for extracting medical details from clinical notes.\n",
    "\n",
    "# Key Components:\n",
    "#   - ChatPromptTemplate: Creates a reusable prompt structure for analyzing clinical notes.\n",
    "#   - SystemMessage: Defines the AI’s role as a medical documentation assistant, ensuring accurate extraction of medical details.\n",
    "#   - HumanMessage: Contains a structured query with a placeholder ({patient_note}), allowing different clinical notes to be analyzed dynamically.\n",
    "#   - prompt_template_notes.invoke({\"patient_note\": note_text}): Fills in the variable \"patient_note\" with the actual clinical note text.\n",
    "#   - model.invoke(prompt): Sends the formatted query to the AI model for processing.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables automated medical text processing, ensuring structured extraction of relevant information such as demographics, chief complaints, medications, and asthma status.\n",
    "# It improves efficiency in clinical documentation and can be integrated into medical record systems for automated analysis.\n",
    "\n",
    "\n",
    "messages_notes = [\n",
    "    (\n",
    "        \"system\", \n",
    "        \"You are an advanced medical documentation assistant with expertise in clinical text analysis. Your task is to review a given clinical note and extract relevant medical details accurately.\"\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        \"human\", \n",
    "        \"Please analyze the following clinical note: {patient_note}. \\n\\n\"\n",
    "        \"Extract and list the following information:\\n\"\n",
    "        \"1. Patient demographics\\n\"\n",
    "        \"2. Chief Complaints\\n\"\n",
    "        \"3. Current Medications\\n\"\n",
    "        \"4. Determine whether the patient has asthma (Yes/No), based on explicit mentions or related diagnoses.\\n\\n\"\n",
    "        \"Provide the output in a structured format.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt_template_notes = ChatPromptTemplate.from_messages(messages_notes)\n"
   ],
   "id": "2f958c9284e3da1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 6. Loading and Reading a Patient Note\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to load a clinical note from a file for further processing.\n",
    "\n",
    "# Key Components:\n",
    "#   - input_dir: Specifies the directory where patient notes are stored.\n",
    "#   - filename: Defines the specific file to be loaded, containing a patient's medical note.\n",
    "#   - os.path.join(input_dir, filename): Constructs the full file path dynamically.\n",
    "#   - open(file_path, \"r\"): Opens the file in read mode and loads the content into the variable \"patient_note\".\n",
    "#   - print(f\"\\nPatient Note:\\n\\n{patient_note}\"): Displays the loaded note for verification.\n",
    "\n",
    "# Purpose:\n",
    "# This step ensures that patient notes are correctly loaded before being analyzed by the AI model.\n",
    "# It enables seamless integration with document processing pipelines for clinical text analysis.\n",
    "\n",
    "\n",
    "input_dir = 'data_prep/patient_notes'\n",
    "filename = 'note_1000000013_20091210.txt' \n",
    "\n",
    "# examples without Asthma: \n",
    "# -----------------------------------------------------------\n",
    "# 1000000002, 1000000003, 1000000009, 1000000010, 1000000013, \n",
    "# 1000000023, 1000000036, 1000000040, 1000000047, 1000000048, \n",
    "# 1000000052, 1000000063, 1000000064, 1000000068, 1000000071, \n",
    "# 1000000082, 1000000086, 1000000087, 1000000093, 1000000101, \n",
    "# 1000000103, 1000000107\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Load the note txt\n",
    "file_path = os.path.join(input_dir, filename)\n",
    "with open(file_path, \"r\") as file:\n",
    "    patient_note = file.read()\n",
    "    \n",
    "print(f\"\\nPatient Note:\\n\\n{patient_note}\")"
   ],
   "id": "ed77019c319ec4f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 7. Invoking the AI Model for Clinical Note Analysis\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to process a patient note using a structured prompt and invoke the AI model for analysis.\n",
    "\n",
    "# Key Components:\n",
    "#   - prompt_template_notes.invoke({\"patient_note\": patient_note}): \n",
    "#     Dynamically fills the prompt template with the actual clinical note text.\n",
    "#   - model.invoke(prompt_notes): \n",
    "#     Sends the formatted query to the AI model for processing.\n",
    "#   - print(result_note.content): \n",
    "#     Displays the AI-generated structured output containing extracted medical details.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables automated extraction of structured medical information from clinical notes.\n",
    "# It ensures efficient and standardized processing of patient data, aiding in medical documentation and decision-making.\n",
    "\n",
    "prompt_notes = prompt_template_notes.invoke({\"patient_note\": patient_note})\n",
    "\n",
    "# invoke model\n",
    "result_note = model.invoke(prompt_notes)\n",
    "print(result_note.content)\n"
   ],
   "id": "43a71ee0339c8ac2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8e7dc8702f5fdc44",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
